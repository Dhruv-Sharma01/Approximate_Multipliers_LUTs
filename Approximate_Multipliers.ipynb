{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMW4hC3qTm8WDKMzkBIJp7g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhruv-Sharma01/Approximate_Multipliers_LUTs/blob/main/Approximate_Multipliers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clear any previous failed builds\n",
        "!rm -rf ~/.cache/torch_extensions/*\n",
        "\n",
        "# tell the build where CUDA lives on Colab\n",
        "import os\n",
        "os.environ[\"CUDA_HOME\"] = \"/usr/local/cuda\"\n",
        "os.environ[\"CUDA_PATH\"] = \"/usr/local/cuda\"\n"
      ],
      "metadata": {
        "id": "Kku7Fp0g-8ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.2 \\\n",
        "            torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1 \\\n",
        "            git+https://github.com/etrommer/torch-approx.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3OyVHrD36nBr",
        "outputId": "bf528c29-f8f0-444e-9d08-02d8bffd5b8f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/etrommer/torch-approx.git\n",
            "  Cloning https://github.com/etrommer/torch-approx.git to /tmp/pip-req-build-s20up3ou\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/etrommer/torch-approx.git /tmp/pip-req-build-s20up3ou\n",
            "  Resolved https://github.com/etrommer/torch-approx.git to commit 34417226bc1f2d2e0fb82cea905b8daa1527be46\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.25.2\n",
            "  Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (4.14.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1) (11.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0) (3.31.6)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m122.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp311-cp311-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m132.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: torchapprox\n",
            "  Building wheel for torchapprox (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchapprox: filename=torchapprox-0.2.0-py3-none-any.whl size=30644 sha256=ca75ce7aa99a974a5ae59b7624577565399f18e1b3f28049fdfe7a2bdefd079b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5g8wte_d/wheels/8b/18/77/417bca4492fbb0616df136820f51920eddbfc8f7c806fcb716\n",
            "Successfully built torchapprox\n",
            "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio, torchapprox\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "blosc2 3.4.0 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.25.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.8 numpy-1.25.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchapprox-0.2.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "a2bb2a97f6dd43c9a23ca5c3503084fd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install libomp-dev ninja-build\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql4auL71-izY",
        "outputId": "03727908-9c8d-4145-95a2-f895a658ffbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libomp-14-dev libomp5-14\n",
            "Suggested packages:\n",
            "  libomp-14-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-14-dev libomp-dev libomp5-14 ninja-build\n",
            "0 upgraded, 4 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 850 kB of archives.\n",
            "After this operation, 9,349 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libomp5-14 amd64 1:14.0.0-1ubuntu1.1 [389 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libomp-14-dev amd64 1:14.0.0-1ubuntu1.1 [347 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ninja-build amd64 1.10.1-1 [111 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libomp-dev amd64 1:14.0-55~exp2 [3,074 B]\n",
            "Fetched 850 kB in 1s (598 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libomp5-14:amd64.\n",
            "(Reading database ... 126319 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5-14_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libomp5-14:amd64 (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package libomp-14-dev.\n",
            "Preparing to unpack .../libomp-14-dev_1%3a14.0.0-1ubuntu1.1_amd64.deb ...\n",
            "Unpacking libomp-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Selecting previously unselected package ninja-build.\n",
            "Preparing to unpack .../ninja-build_1.10.1-1_amd64.deb ...\n",
            "Unpacking ninja-build (1.10.1-1) ...\n",
            "Selecting previously unselected package libomp-dev:amd64.\n",
            "Preparing to unpack .../libomp-dev_1%3a14.0-55~exp2_amd64.deb ...\n",
            "Unpacking libomp-dev:amd64 (1:14.0-55~exp2) ...\n",
            "Setting up libomp5-14:amd64 (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up ninja-build (1.10.1-1) ...\n",
            "Setting up libomp-14-dev (1:14.0.0-1ubuntu1.1) ...\n",
            "Setting up libomp-dev:amd64 (1:14.0-55~exp2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psutil GPUtil"
      ],
      "metadata": {
        "id": "HrrSch6Y5hSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab cell 1: setup monitoring + monkey‑patch\n",
        "!pip install -q psutil\n",
        "\n",
        "import time, threading, subprocess\n",
        "import psutil\n",
        "import torch.nn as nn\n",
        "\n",
        "# — CPU/GPU logger\n",
        "LOG_INTERVAL = 1.0  # seconds\n",
        "\n",
        "def usage_logger(stop_event):\n",
        "    while not stop_event.is_set():\n",
        "        cpu = psutil.cpu_percent(interval=None)\n",
        "        try:\n",
        "            out = subprocess.check_output([\n",
        "                \"nvidia-smi\",\n",
        "                \"--query-gpu=utilization.gpu,memory.used,memory.total\",\n",
        "                \"--format=csv,noheader,nounits\"\n",
        "            ]).decode().strip()\n",
        "            gpu_util, mem_used, mem_total = map(float, out.split(\", \"))\n",
        "            gpu_mem_pct = mem_used / mem_total * 100\n",
        "            gpu_str = f\"GPU: {gpu_util:.1f}%  Mem: {gpu_mem_pct:.1f}%\"\n",
        "        except:\n",
        "            gpu_str = \"GPU: n/a\"\n",
        "        print(f\"[{time.strftime('%H:%M:%S')}] CPU: {cpu:.1f}%  {gpu_str}\")\n",
        "        stop_event.wait(LOG_INTERVAL)\n",
        "\n",
        "stop_event = threading.Event()\n",
        "threading.Thread(target=usage_logger, args=(stop_event,), daemon=True).start()\n",
        "\n",
        "# — monkey‑patch guards\n",
        "if not hasattr(nn.Conv2d, \"_orig_forward\"):\n",
        "    nn.Conv2d._orig_forward = nn.Conv2d.forward\n",
        "    def _conv2d_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Conv2d._orig_forward(self, x)\n",
        "    nn.Conv2d.forward = _conv2d_forward_patched\n",
        "\n",
        "if not hasattr(nn.Linear, \"_orig_forward\"):\n",
        "    nn.Linear._orig_forward = nn.Linear.forward\n",
        "    def _linear_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Linear._orig_forward(self, x)\n",
        "    nn.Linear.forward = _linear_forward_patched\n"
      ],
      "metadata": {
        "id": "CkIO64tY6jEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.ao.quantization as quant\n",
        "import torchapprox.layers as tal\n",
        "from torchapprox.utils import wrap_quantizable, get_approx_modules\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ─── Monkey‑patch Conv2d & Linear to ignore extra stub args ───────────────────\n",
        "# Save originals\n",
        "_orig_conv2d_forward = nn.Conv2d.forward\n",
        "_orig_linear_forward = nn.Linear.forward\n",
        "\n",
        "# Define patched versions\n",
        "def _conv2d_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "    # ApproxWrapper passes (x, scale, zp) during calibration.\n",
        "    return _orig_conv2d_forward(self, x)\n",
        "\n",
        "def _linear_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "    # Similarly for Linear layers.\n",
        "    return _orig_linear_forward(self, x)\n",
        "\n",
        "# Apply patches\n",
        "nn.Conv2d.forward = _conv2d_forward_patched\n",
        "nn.Linear.forward = _linear_forward_patched\n",
        "\n",
        "# ─── 0) Define LeNet ──────────────────────────────────────────────────────────\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6,16,5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120,  84)\n",
        "        self.fc3   = nn.Linear( 84,  10)\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "# ─── 1) Prepare data loaders ───────────────────────────────────────────────────\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_ds = datasets.MNIST('.', train=True,  download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST('.', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_ds,  batch_size=512, shuffle=False)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ─── 2) Train FP32 LeNet ──────────────────────────────────────────────────────\n",
        "model = LeNet().to(device)\n",
        "opt   = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "epochs = 5\n",
        "\n",
        "for ep in range(1, epochs+1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labs in train_loader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss   = F.cross_entropy(logits, labs)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    avg_loss = total_loss / len(train_ds)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labs in test_loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            preds = model(imgs).argmax(dim=1)\n",
        "            correct += (preds == labs).sum().item()\n",
        "    acc = 100 * correct / len(test_ds)\n",
        "    print(f\"Epoch {ep}/{epochs} — Loss: {avg_loss:.4f}  Test Acc: {acc:.2f}%\")\n",
        "\n",
        "# ─── 3) Wrap + patch wrapper forward ───────────────────────────────────────────\n",
        "model.eval()\n",
        "wrap_quantizable(model)\n",
        "mapping = tal.layer_mapping_dict()\n",
        "\n",
        "import torch.nn.functional as F\n",
        "for _, layer in get_approx_modules(model):\n",
        "    def _wrapper_forward(self, x, layer=layer):\n",
        "        w_hat = layer.weight_hat.to(x.dtype)\n",
        "        b_hat = (layer.bias_hat.to(x.dtype)\n",
        "                 if getattr(layer, \"bias_hat\", None) is not None\n",
        "                 else None)\n",
        "        return F.conv2d(\n",
        "            x,\n",
        "            w_hat,\n",
        "            bias=b_hat,\n",
        "            stride=layer.wrapped.stride,\n",
        "            padding=layer.wrapped.padding,\n",
        "            dilation=layer.wrapped.dilation,\n",
        "            groups=layer.wrapped.groups\n",
        "        )\n",
        "    layer.forward = _wrapper_forward.__get__(layer, layer.__class__)\n",
        "\n",
        "# ─── 4) Prepare observers & quant stubs ────────────────────────────────────────\n",
        "quant.prepare(model, mapping)\n",
        "model.to(device)\n",
        "\n",
        "# ─── 5) Calibration pass ──────────────────────────────────────────────────────\n",
        "with torch.no_grad():\n",
        "    imgs, _ = next(iter(train_loader))\n",
        "    imgs = imgs.to(device)\n",
        "    model(imgs)  # ← now passes without TypeError\n",
        "\n",
        "# ─── 6) Convert to true quantized kernels ─────────────────────────────────────\n",
        "quant.convert(model, mapping)\n",
        "\n",
        "# ─── 7) Build LUT variants ────────────────────────────────────────────────────\n",
        "x = np.arange(256, dtype=np.int32)\n",
        "x[x>=128] -= 256\n",
        "xx, yy = np.meshgrid(x, x, indexing='ij')\n",
        "lut_exact   = xx * yy\n",
        "lut_half    = np.rint(lut_exact/2).astype(np.int32)\n",
        "lut_quarter = np.rint(lut_exact/4).astype(np.int32)\n",
        "luts   = [lut_exact, lut_half, lut_quarter]\n",
        "labels = [\"Exact (Quant)\", \"Approx×½\", \"Approx×¼\"]\n",
        "\n",
        "# ─── 8) Inference & measure accuracy ──────────────────────────────────────────\n",
        "accuracies = []\n",
        "for idx, lut in enumerate(luts):\n",
        "    for _, layer in get_approx_modules(model):\n",
        "        if idx == 0:\n",
        "            layer.inference_mode = tal.InferenceMode.QUANTIZED\n",
        "        else:\n",
        "            layer.inference_mode = tal.InferenceMode.APPROXIMATE\n",
        "            layer.lut = lut\n",
        "\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labs in test_loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            preds = model(imgs).argmax(dim=1)\n",
        "            correct += (preds == labs).sum().item()\n",
        "    acc = 100 * correct / len(test_ds)\n",
        "    accuracies.append(acc)\n",
        "    print(f\"{labels[idx]} → {acc:.2f}%\")\n",
        "\n",
        "# ─── 9) Plot comparison ───────────────────────────────────────────────────────\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(labels, accuracies, marker='o')\n",
        "plt.title(\"MNIST Accuracy: Quant vs. Approx Multipliers\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l8LuD1Brfcva",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "7fd89bfc-47da-4ced-c92d-98faccdf8df8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-3526526616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# ─── 3) Build lookup tables ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m luts = {v: np.array([[approx_mul(a,b,v) for b in range(256)]\n\u001b[0m\u001b[1;32m    119\u001b[0m                      for a in range(256)], dtype=np.uint16)\n\u001b[1;32m    120\u001b[0m         for v in ['Yang1','Lin','Ha','Hybrid']}\n",
            "\u001b[0;32m/tmp/ipython-input-3-3526526616.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# ─── 3) Build lookup tables ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m luts = {v: np.array([[approx_mul(a,b,v) for b in range(256)]\n\u001b[0m\u001b[1;32m    119\u001b[0m                      for a in range(256)], dtype=np.uint16)\n\u001b[1;32m    120\u001b[0m         for v in ['Yang1','Lin','Ha','Hybrid']}\n",
            "\u001b[0;32m/tmp/ipython-input-3-3526526616.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# ─── 3) Build lookup tables ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m luts = {v: np.array([[approx_mul(a,b,v) for b in range(256)]\n\u001b[0m\u001b[1;32m    119\u001b[0m                      for a in range(256)], dtype=np.uint16)\n\u001b[1;32m    120\u001b[0m         for v in ['Yang1','Lin','Ha','Hybrid']}\n",
            "\u001b[0;32m/tmp/ipython-input-3-3526526616.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# ─── 3) Build lookup tables ───────────────────────────────────────────────────\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m luts = {v: np.array([[approx_mul(a,b,v) for b in range(256)]\n\u001b[0m\u001b[1;32m    119\u001b[0m                      for a in range(256)], dtype=np.uint16)\n\u001b[1;32m    120\u001b[0m         for v in ['Yang1','Lin','Ha','Hybrid']}\n",
            "\u001b[0;32m/tmp/ipython-input-3-3526526616.py\u001b[0m in \u001b[0;36mapprox_mul\u001b[0;34m(a, b, variant)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnew_pp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mby_w\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Hybrid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_event.set()"
      ],
      "metadata": {
        "id": "L7Zfz6R7odKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "277fa477-f394-4a6c-c661-64c025f1a828",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22:13:03] CPU: 58.6%  GPU: 0.0%  Mem: 1.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = [\"Exact (Quant)\", \"Approx×½\", \"Approx×¼\"]\n",
        "accuracies = [98.58, 98.55, 98.56]\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(labels, accuracies, marker='o')\n",
        "plt.title(\"MNIST Accuracy: Quant vs. Approx Multipliers\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.ylim(min(accuracies) - 0.1, max(accuracies) + 0.1)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "LCN7tZhS9EH9",
        "outputId": "a1a7bec1-62da-401a-ae39-7250d173687a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Proposed Variants"
      ],
      "metadata": {
        "id": "hJxBJl3vrn8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.ao.quantization as quant\n",
        "import torchapprox.layers as tal\n",
        "from torchapprox.utils import wrap_quantizable, get_approx_modules\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ─── 0) Guarded monkey-patch for Conv2d & Linear ───────────────────────────────\n",
        "if not hasattr(nn.Conv2d, \"_orig_forward\"):\n",
        "    nn.Conv2d._orig_forward = nn.Conv2d.forward\n",
        "    def _conv2d_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Conv2d._orig_forward(self, x)\n",
        "    nn.Conv2d.forward = _conv2d_forward_patched\n",
        "\n",
        "if not hasattr(nn.Linear, \"_orig_forward\"):\n",
        "    nn.Linear._orig_forward = nn.Linear.forward\n",
        "    def _linear_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Linear._orig_forward(self, x)\n",
        "    nn.Linear.forward = _linear_forward_patched\n",
        "\n",
        "# ─── 1) Compressor truth‐tables ────────────────────────────────────────────────\n",
        "def make_yang1_table():\n",
        "    t={}\n",
        "    for bits in range(16):\n",
        "        x=[(bits>>i)&1 for i in range(4)]\n",
        "        s=sum(x)\n",
        "        t[tuple(x)] = (1,1) if s>=3 else ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_lin_table():\n",
        "    t={}\n",
        "    for bits in range(16):\n",
        "        x=[(bits>>i)&1 for i in range(4)]\n",
        "        s=sum(x)\n",
        "        t[tuple(x)] = (1,0) if s==4 else ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_ha_table():\n",
        "    t={}\n",
        "    for bits in range(16):\n",
        "        x1,x2,x3,x4 = ((bits>>i)&1 for i in range(4))\n",
        "        s = x1+x2+x3+x4\n",
        "        if x3 and x4: s-=1\n",
        "        t[(x1,x2,x3,x4)] = ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_ahma_table():\n",
        "    return {\n",
        "        (0,0,0,0):(0,0),(0,0,0,1):(0,1),(0,0,1,0):(0,1),(0,0,1,1):(1,0),\n",
        "        (0,1,0,0):(0,1),(0,1,0,1):(1,0),(0,1,1,0):(1,0),(0,1,1,1):(1,1),\n",
        "        (1,0,0,0):(0,1),(1,0,0,1):(1,0),(1,0,1,0):(1,0),(1,0,1,1):(1,1),\n",
        "        (1,1,0,0):(1,0),(1,1,0,1):(1,1),(1,1,1,0):(1,1),(1,1,1,1):(1,1),\n",
        "    }\n",
        "\n",
        "def make_proposed_table():\n",
        "    t={}\n",
        "    for bits in range(16):\n",
        "        x=[(bits>>i)&1 for i in range(4)]\n",
        "        w1 = x[0] or x[1]\n",
        "        w2 = x[2] or (x[0] and x[1])\n",
        "        w3 = x[3]\n",
        "        s = w1 + w2 + w3\n",
        "        t[tuple(x)] = ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "YANG1_T = make_yang1_table()\n",
        "LIN_T   = make_lin_table()\n",
        "HA_T    = make_ha_table()\n",
        "AHMA_T  = make_ahma_table()\n",
        "PROP_T  = make_proposed_table()\n",
        "COMP_TABLES = {'Yang1':YANG1_T, 'Lin':LIN_T, 'Ha':HA_T}\n",
        "\n",
        "# ─── 2) Column reduction helper ────────────────────────────────────────────────\n",
        "def reduce_column(bits, table):\n",
        "    out=[]; i=0\n",
        "    while i+3 < len(bits):\n",
        "        grp=bits[i:i+4]\n",
        "        vals=tuple(b for b,_ in grp)\n",
        "        C,S = table[vals]\n",
        "        w = grp[0][1]\n",
        "        out += [(S,w), (C,w*2)]\n",
        "        i+=4\n",
        "    out.extend(bits[i:])\n",
        "    return out\n",
        "\n",
        "# ─── 3) Approximate 8×8 C–N multiply ──────────────────────────────────────────\n",
        "def approx_mul(a, b, variant):\n",
        "    # partial products\n",
        "    pp=[(((a>>i)&1)&((b>>j)&1), 1<<j) for i in range(8) for j in range(8)]\n",
        "    # 4 reduction stages\n",
        "    for _ in range(4):\n",
        "        by_w={}\n",
        "        for bit,w in pp: by_w.setdefault(w,[]).append((bit,w))\n",
        "        new_pp=[]\n",
        "        for w,grp in by_w.items():\n",
        "            col=int(np.log2(w))\n",
        "            if col<8:\n",
        "                if variant=='Hybrid':\n",
        "                    tbl = AHMA_T if col<6 else PROP_T\n",
        "                else:\n",
        "                    tbl = COMP_TABLES[variant]\n",
        "                new_pp += reduce_column(grp, tbl)\n",
        "            else:\n",
        "                s=sum(b for b,_ in grp)\n",
        "                new_pp += [(s&1, w), ((s>>1)&1, w*2)]\n",
        "        pp=new_pp\n",
        "    return sum(bit*w for bit,w in pp)\n",
        "\n",
        "# ─── 4) Build 256×256 signed LUTs ─────────────────────────────────────────────\n",
        "luts = {\n",
        "    v: np.array([[approx_mul(a,b,v) for b in range(256)]\n",
        "                 for a in range(256)], dtype=np.int32)\n",
        "    for v in ['Yang1','Lin','Ha','Hybrid']\n",
        "}\n",
        "\n",
        "# ─── 5) Data & Model Setup ────────────────────────────────────────────────────\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize(32),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "train_ds = datasets.MNIST('.', train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST('.', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=256, shuffle=True)\n",
        "test_loader  = torch.utils.data.DataLoader(test_ds, batch_size=256, shuffle=False)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = models.resnet18(pretrained=False, num_classes=10)\n",
        "model.conv1 = nn.Conv2d(3,64,7,2,3,bias=False)\n",
        "model.to(device)\n",
        "\n",
        "# ─── 6) Train FP32 ResNet on MNIST ─────────────────────────────────────────────\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "for ep in range(5):\n",
        "    model.train()\n",
        "    for imgs,labs in train_loader:\n",
        "        imgs,labs = imgs.to(device), labs.to(device)\n",
        "        opt.zero_grad()\n",
        "        F.cross_entropy(model(imgs), labs).backward()\n",
        "        opt.step()\n",
        "    print(f\"Epoch {ep+1}/5 complete\")\n",
        "\n",
        "# ─── 7) Quantization Prep & Calibration ───────────────────────────────────────\n",
        "model.eval()\n",
        "wrap_quantizable(model)\n",
        "# patch each approx‐wrapper to use functional conv2d\n",
        "import torch.nn.functional as _F\n",
        "for _,layer in get_approx_modules(model):\n",
        "    def fw(x, layer=layer):\n",
        "        w_hat = layer.weight_hat.to(x.dtype)\n",
        "        b_hat = getattr(layer,'bias_hat',None)\n",
        "        return _F.conv2d(x, w_hat,\n",
        "                        bias=(b_hat.to(x.dtype) if b_hat is not None else None),\n",
        "                        stride=layer.wrapped.stride,\n",
        "                        padding=layer.wrapped.padding,\n",
        "                        dilation=layer.wrapped.dilation,\n",
        "                        groups=layer.wrapped.groups)\n",
        "    layer.forward = fw.__get__(layer, layer.__class__)\n",
        "\n",
        "mapping = tal.layer_mapping_dict()\n",
        "quant.prepare(model, mapping)\n",
        "with torch.no_grad():\n",
        "    for i,(imgs,_) in enumerate(train_loader):\n",
        "        model(imgs.to(device))\n",
        "        if i>=5: break\n",
        "quant.convert(model, mapping)\n",
        "\n",
        "# ─── 8) Inference & Accuracy Comparison ──────────────────────────────────────\n",
        "results = {}\n",
        "for variant, lut in luts.items():\n",
        "    for _,layer in get_approx_modules(model):\n",
        "        if variant=='Yang1':\n",
        "            layer.inference_mode = tal.InferenceMode.QUANTIZED\n",
        "        else:\n",
        "            layer.inference_mode = tal.InferenceMode.APPROXIMATE\n",
        "            layer.lut = lut\n",
        "\n",
        "    correct=0\n",
        "    with torch.no_grad():\n",
        "        for imgs,labs in test_loader:\n",
        "            imgs,labs = imgs.to(device), labs.to(device)\n",
        "            preds = model(imgs).argmax(1)\n",
        "            correct += (preds==labs).sum().item()\n",
        "    acc = 100*correct/len(test_ds)\n",
        "    results[variant]=acc\n",
        "    print(f\"{variant}: {acc:.2f}%\")\n",
        "\n",
        "# ─── 9) Plot Results ──────────────────────────────────────────────────────────\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(results.keys(), results.values())\n",
        "plt.title(\"MNIST Accuracy: 8×8 C–N Variants\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.ylim(0,100)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GpFZlLEt9Qty",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "30852331-6ee3-46aa-f119-35ad65a29da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: ./MNIST/raw/train-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Using downloaded and verified file: ./MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Using downloaded and verified file: ./MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5887060.81it/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Epoch 1/5 complete\n",
            "Epoch 2/5 complete\n",
            "Epoch 3/5 complete\n",
            "Epoch 4/5 complete\n",
            "Epoch 5/5 complete\n",
            "Yang1: 98.99%\n",
            "Lin: 99.02%\n",
            "Ha: 99.04%\n",
            "Hybrid: 99.03%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Suppose `luts` is your dict of 256×256 arrays\n",
        "# e.g. luts = {'Yang1': lut_yang1, 'Lin': lut_lin, …}\n",
        "\n",
        "# (a) Save each LUT individually:\n",
        "for variant, lut in luts.items():\n",
        "    np.save(f\"lut_{variant}.npy\", lut)\n",
        "# This writes files: lut_Yang1.npy, lut_Lin.npy, etc.\n",
        "\n",
        "# (b) Or bundle them all into one .npz archive:\n",
        "np.savez(\"luts_all.npz\", **luts)\n"
      ],
      "metadata": {
        "id": "X0hmqe-qsZFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── Evaluate Exact Quantized Model Accuracy ──────────────────────────────────\n",
        "def eval_quantized_accuracy(model, data_loader, device):\n",
        "    model.eval()\n",
        "    # Force every approx‐wrapper to use the exact quantized kernels\n",
        "    for _, layer in get_approx_modules(model):\n",
        "        layer.inference_mode = tal.InferenceMode.QUANTIZED\n",
        "\n",
        "    correct = 0\n",
        "    total   = 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labs in data_loader:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            preds = model(imgs).argmax(dim=1)\n",
        "            correct += (preds == labs).sum().item()\n",
        "            total   += labs.size(0)\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# After quant.convert(...)\n",
        "quant.convert(model, mapping)\n",
        "\n",
        "# Compute and print accuracy\n",
        "exact_acc = eval_quantized_accuracy(model, test_loader, device)\n",
        "print(f\"Exact quantized accuracy: {exact_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DmUl3eE0c_x",
        "outputId": "36113d8b-483f-4452-c38e-389c91488335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact quantized accuracy: 99.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.ao.quantization as quant\n",
        "import torchapprox.layers as tal\n",
        "from torchapprox.utils import wrap_quantizable, get_approx_modules\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ─── 1) Guarded monkey-patch Conv2d & Linear ──────────────────────────────────\n",
        "if not hasattr(nn.Conv2d, \"_orig_forward\"):\n",
        "    nn.Conv2d._orig_forward = nn.Conv2d.forward\n",
        "    def _conv2d_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Conv2d._orig_forward(self, x)\n",
        "    nn.Conv2d.forward = _conv2d_forward_patched\n",
        "\n",
        "if not hasattr(nn.Linear, \"_orig_forward\"):\n",
        "    nn.Linear._orig_forward = nn.Linear.forward\n",
        "    def _linear_forward_patched(self, x, x_scale=None, x_zero_point=None):\n",
        "        return nn.Linear._orig_forward(self, x)\n",
        "    nn.Linear.forward = _linear_forward_patched\n",
        "\n",
        "# ─── 2) Compressor truth-tables ────────────────────────────────────────────────\n",
        "def make_yang1_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits>>i)&1 for i in range(4)]\n",
        "        s = sum(x)\n",
        "        t[tuple(x)] = (1,1) if s>=3 else ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_lin_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits>>i)&1 for i in range(4)]\n",
        "        s = sum(x)\n",
        "        t[tuple(x)] = (1,0) if s==4 else ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_ha_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x1,x2,x3,x4 = ((bits>>i)&1 for i in range(4))\n",
        "        s = x1+x2+x3+x4\n",
        "        if x3 and x4: s -= 1\n",
        "        t[(x1,x2,x3,x4)] = ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "def make_ahma_table():\n",
        "    return {\n",
        "      (0,0,0,0):(0,0),(0,0,0,1):(0,1),(0,0,1,0):(0,1),(0,0,1,1):(1,0),\n",
        "      (0,1,0,0):(0,1),(0,1,0,1):(1,0),(0,1,1,0):(1,0),(0,1,1,1):(1,1),\n",
        "      (1,0,0,0):(0,1),(1,0,0,1):(1,0),(1,0,1,0):(1,0),(1,0,1,1):(1,1),\n",
        "      (1,1,0,0):(1,0),(1,1,0,1):(1,1),(1,1,1,0):(1,1),(1,1,1,1):(1,1),\n",
        "    }\n",
        "\n",
        "def make_proposed_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits>>i)&1 for i in range(4)]\n",
        "        w1 = x[0] or x[1]\n",
        "        w2 = x[2] or (x[0] and x[1])\n",
        "        w3 = x[3]\n",
        "        s = w1 + w2 + w3\n",
        "        t[tuple(x)] = ((s>>1)&1, s&1)\n",
        "    return t\n",
        "\n",
        "YANG1_T = make_yang1_table()\n",
        "LIN_T   = make_lin_table()\n",
        "HA_T    = make_ha_table()\n",
        "AHMA_T  = make_ahma_table()\n",
        "PROP_T  = make_proposed_table()\n",
        "COMP_TABLES = {'Yang1':YANG1_T, 'Lin':LIN_T, 'Ha':HA_T}\n",
        "\n",
        "# ─── 3) Column‐reduction helper ────────────────────────────────────────────────\n",
        "def reduce_column(bits, table):\n",
        "    out=[]; i=0\n",
        "    while i+3 < len(bits):\n",
        "        grp=bits[i:i+4]\n",
        "        vals=tuple(b for b,_ in grp)\n",
        "        C,S=table[vals]\n",
        "        w=grp[0][1]\n",
        "        out+=[(S,w),(C,w*2)]\n",
        "        i+=4\n",
        "    out.extend(bits[i:])\n",
        "    return out\n",
        "\n",
        "# ─── 4) Approximate 8×8 C–N multiply ───────────────────────────────────────────\n",
        "def approx_mul(a, b, variant):\n",
        "    pp=[(((a>>i)&1)&((b>>j)&1),1<<j) for i in range(8) for j in range(8)]\n",
        "    for _ in range(4):\n",
        "        by_w={}\n",
        "        for bit,w in pp: by_w.setdefault(w,[]).append((bit,w))\n",
        "        new_pp=[]\n",
        "        for w,grp in by_w.items():\n",
        "            col=int(math.log2(w))\n",
        "            if col<8:\n",
        "                if variant=='Hybrid':\n",
        "                    tbl = AHMA_T if col<6 else PROP_T\n",
        "                else:\n",
        "                    tbl = COMP_TABLES[variant]\n",
        "                new_pp+=reduce_column(grp,tbl)\n",
        "            else:\n",
        "                s=sum(b for b,_ in grp)\n",
        "                new_pp+=[(s&1,w),((s>>1)&1,w*2)]\n",
        "        pp=new_pp\n",
        "    return sum(bit*w for bit,w in pp)\n",
        "\n",
        "# ─── 5) Build signed‐int32 LUTs ───────────────────────────────────────────────\n",
        "variants=['Yang1','Lin','Ha','Hybrid']\n",
        "luts={v: np.array([[approx_mul(a,b,v) for b in range(256)]\n",
        "                  for a in range(256)],dtype=np.int32)\n",
        "      for v in variants}\n",
        "\n",
        "# ─── 6) Data Loaders (CIFAR-10) ────────────────────────────────────────────────\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n",
        "])\n",
        "train_ds = datasets.CIFAR10('.',train=True,download=True,transform=transform)\n",
        "test_ds  = datasets.CIFAR10('.',train=False,download=True,transform=transform)\n",
        "train_loader = DataLoader(train_ds,batch_size=128,shuffle=True,num_workers=2)\n",
        "test_loader  = DataLoader(test_ds, batch_size=256,shuffle=False,num_workers=2)\n",
        "calib_loader = DataLoader(train_ds,batch_size=256,shuffle=True,num_workers=2)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ─── 7) Helper: Quant-Prep & Convert ──────────────────────────────────────────\n",
        "def prepare_and_convert(model, calib_loader, num_calib=5):\n",
        "    model.eval()\n",
        "    wrap_quantizable(model)\n",
        "    import torch.nn.functional as _F\n",
        "    for _,layer in get_approx_modules(model):\n",
        "        def fw(x,layer=layer):\n",
        "            w=layer.weight_hat.to(x.dtype)\n",
        "            b=getattr(layer,'bias_hat',None)\n",
        "            return _F.conv2d(x,w,(b.to(x.dtype) if b is not None else None),\n",
        "                             stride=layer.wrapped.stride,\n",
        "                             padding=layer.wrapped.padding,\n",
        "                             dilation=layer.wrapped.dilation,\n",
        "                             groups=layer.wrapped.groups)\n",
        "        layer.forward=fw.__get__(layer,layer.__class__)\n",
        "    mapping=tal.layer_mapping_dict()\n",
        "    quant.prepare(model,mapping)\n",
        "    with torch.no_grad():\n",
        "        for i,(imgs,_) in enumerate(calib_loader):\n",
        "            model(imgs.to(device))\n",
        "            if i+1>=num_calib: break\n",
        "    quant.convert(model,mapping)\n",
        "    return mapping\n",
        "\n",
        "# ─── 8) Helper: Evaluate Variants ─────────────────────────────────────────────\n",
        "def evaluate_variants(model,data_loader):\n",
        "    results={}\n",
        "    for v,lut in luts.items():\n",
        "        for _,layer in get_approx_modules(model):\n",
        "            if v=='Yang1':\n",
        "                layer.inference_mode=tal.InferenceMode.QUANTIZED\n",
        "            else:\n",
        "                layer.inference_mode=tal.InferenceMode.APPROXIMATE\n",
        "                layer.lut=lut\n",
        "        correct,total=0,0\n",
        "        with torch.no_grad():\n",
        "            for imgs,labs in data_loader:\n",
        "                imgs,labs=imgs.to(device),labs.to(device)\n",
        "                preds=model(imgs).argmax(1)\n",
        "                correct+= (preds==labs).sum().item()\n",
        "                total+= labs.size(0)\n",
        "        results[v]=100*correct/total\n",
        "    return results\n",
        "\n",
        "# ─── 9) Model Loop: ResNet18, AlexNet, VGG16_BN, MobileNetV2 ─────────────────\n",
        "for name, constructor in [\n",
        "    ('ResNet18',    models.resnet18),\n",
        "    ('AlexNet',     models.alexnet),\n",
        "    ('MobileNetV2', models.mobilenet_v2),\n",
        "    # ('VGG16_BN',    models.vgg16_bn),\n",
        "]:\n",
        "    print(f\"\\n===== {name} =====\")\n",
        "    model = constructor(pretrained=True)\n",
        "\n",
        "    # → Adapt final layer\n",
        "    if name == 'ResNet18':\n",
        "        model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "    elif name == 'MobileNetV2':\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, 10)\n",
        "    else:\n",
        "        model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, 10)\n",
        "\n",
        "    # → For VGG only: freeze features + smaller batch\n",
        "    if name == 'VGG16_BN':\n",
        "        for p in model.features.parameters():\n",
        "            p.requires_grad = False\n",
        "        vgg_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\n",
        "        train_iter = vgg_loader\n",
        "    else:\n",
        "        train_iter = train_loader\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # → Fine-tune classifier / full model\n",
        "    opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "    for ep in range(3):\n",
        "        model.train()\n",
        "        for imgs, labs in train_iter:\n",
        "            imgs, labs = imgs.to(device), labs.to(device)\n",
        "            opt.zero_grad()\n",
        "            F.cross_entropy(model(imgs), labs).backward()\n",
        "            opt.step()\n",
        "        print(f\"{name} Epoch {ep+1}/3 complete\")\n",
        "\n",
        "    # → Quantize & LUT‐approximate\n",
        "    prepare_and_convert(model, calib_loader, num_calib=5)\n",
        "\n",
        "    # → Evaluate & print\n",
        "    res = evaluate_variants(model, test_loader)\n",
        "    for v, acc in res.items():\n",
        "        print(f\"  {v:8s}: {acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vc0QGhc1885",
        "outputId": "d89b00a7-99ca-4aab-85d8-4ac3cad75fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 32377907.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to .\n",
            "Files already downloaded and verified\n",
            "\n",
            "===== ResNet18 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 255MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet18 Epoch 1/3 complete\n",
            "ResNet18 Epoch 2/3 complete\n",
            "ResNet18 Epoch 3/3 complete\n",
            "  Yang1   : 91.29%\n",
            "  Lin     : 91.45%\n",
            "  Ha      : 91.49%\n",
            "  Hybrid  : 91.43%\n",
            "\n",
            "===== AlexNet =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:05<00:00, 42.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet Epoch 1/3 complete\n",
            "AlexNet Epoch 2/3 complete\n",
            "AlexNet Epoch 3/3 complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Yang1   : 88.94%\n",
            "  Lin     : 88.79%\n",
            "  Ha      : 88.72%\n",
            "  Hybrid  : 88.73%\n",
            "\n",
            "===== MobileNetV2 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 121MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MobileNetV2 Epoch 1/3 complete\n",
            "MobileNetV2 Epoch 2/3 complete\n",
            "MobileNetV2 Epoch 3/3 complete\n",
            "  Yang1   : 39.49%\n",
            "  Lin     : 41.69%\n",
            "  Ha      : 42.25%\n",
            "  Hybrid  : 40.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class VGG8(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG8, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 256), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.classifier(x)\n"
      ],
      "metadata": {
        "id": "5sOXH1iT4ytR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG8().to(device)\n"
      ],
      "metadata": {
        "id": "NPp0pLPq9VOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.ao.quantization as quant\n",
        "import torchapprox.layers as tal\n",
        "from torchapprox.utils import wrap_quantizable, get_approx_modules\n",
        "import numpy as np\n",
        "import math\n",
        "import gc\n",
        "\n",
        "# ─── Setup ───────────────────────────────────────────────────────────────\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# ─── 1. Define VGG8 model ────────────────────────────────────────────────\n",
        "class VGG8(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG8, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 4 * 4, 256), nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ─── 2. Transform + Data ──────────────────────────────────────────────────\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "train_ds = datasets.CIFAR10(root='.', train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.CIFAR10(root='.', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False, num_workers=2)\n",
        "calib_loader = DataLoader(train_ds, batch_size=256, shuffle=True, num_workers=2)\n",
        "\n",
        "# ─── 3. Compressor LUTs ───────────────────────────────────────────────────\n",
        "def make_yang1_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits >> i) & 1 for i in range(4)]\n",
        "        s = sum(x)\n",
        "        t[tuple(x)] = (1, 1) if s >= 3 else ((s >> 1) & 1, s & 1)\n",
        "    return t\n",
        "\n",
        "def make_lin_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits >> i) & 1 for i in range(4)]\n",
        "        s = sum(x)\n",
        "        t[tuple(x)] = (1, 0) if s == 4 else ((s >> 1) & 1, s & 1)\n",
        "    return t\n",
        "\n",
        "def make_ha_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x1, x2, x3, x4 = ((bits >> i) & 1 for i in range(4))\n",
        "        s = x1 + x2 + x3 + x4\n",
        "        if x3 and x4: s -= 1\n",
        "        t[(x1, x2, x3, x4)] = ((s >> 1) & 1, s & 1)\n",
        "    return t\n",
        "\n",
        "def make_ahma_table():\n",
        "    return {\n",
        "      (0,0,0,0):(0,0),(0,0,0,1):(0,1),(0,0,1,0):(0,1),(0,0,1,1):(1,0),\n",
        "      (0,1,0,0):(0,1),(0,1,0,1):(1,0),(0,1,1,0):(1,0),(0,1,1,1):(1,1),\n",
        "      (1,0,0,0):(0,1),(1,0,0,1):(1,0),(1,0,1,0):(1,0),(1,0,1,1):(1,1),\n",
        "      (1,1,0,0):(1,0),(1,1,0,1):(1,1),(1,1,1,0):(1,1),(1,1,1,1):(1,1),\n",
        "    }\n",
        "\n",
        "def make_proposed_table():\n",
        "    t = {}\n",
        "    for bits in range(16):\n",
        "        x = [(bits >> i) & 1 for i in range(4)]\n",
        "        w1 = x[0] or x[1]\n",
        "        w2 = x[2] or (x[0] and x[1])\n",
        "        w3 = x[3]\n",
        "        s = w1 + w2 + w3\n",
        "        t[tuple(x)] = ((s >> 1) & 1, s & 1)\n",
        "    return t\n",
        "\n",
        "COMP_TABLES = {\n",
        "    'Yang1': make_yang1_table(),\n",
        "    'Lin': make_lin_table(),\n",
        "    'Ha': make_ha_table()\n",
        "}\n",
        "AHMA_T = make_ahma_table()\n",
        "PROP_T = make_proposed_table()\n",
        "\n",
        "def reduce_column(bits, table):\n",
        "    out = []; i = 0\n",
        "    while i+3 < len(bits):\n",
        "        grp = bits[i:i+4]\n",
        "        vals = tuple(b for b, _ in grp)\n",
        "        C, S = table[vals]\n",
        "        w = grp[0][1]\n",
        "        out += [(S, w), (C, w*2)]\n",
        "        i += 4\n",
        "    out.extend(bits[i:])\n",
        "    return out\n",
        "\n",
        "def approx_mul(a, b, variant):\n",
        "    pp = [(((a >> i) & 1) & ((b >> j) & 1), 1 << j) for i in range(8) for j in range(8)]\n",
        "    for _ in range(4):\n",
        "        by_w = {}\n",
        "        for bit, w in pp:\n",
        "            by_w.setdefault(w, []).append((bit, w))\n",
        "        new_pp = []\n",
        "        for w, grp in by_w.items():\n",
        "            col = int(math.log2(w))\n",
        "            if col < 8:\n",
        "                tbl = AHMA_T if (variant == 'Hybrid' and col < 6) else PROP_T if variant == 'Hybrid' else COMP_TABLES[variant]\n",
        "                new_pp += reduce_column(grp, tbl)\n",
        "            else:\n",
        "                s = sum(b for b, _ in grp)\n",
        "                new_pp += [(s & 1, w), ((s >> 1) & 1, w * 2)]\n",
        "        pp = new_pp\n",
        "    return sum(bit * w for bit, w in pp)\n",
        "\n",
        "luts = {v: np.array([[approx_mul(a, b, v) for b in range(256)] for a in range(256)], dtype=np.int32)\n",
        "        for v in ['Yang1', 'Lin', 'Ha', 'Hybrid']}\n",
        "\n",
        "# ─── 4. Quantization Helpers ─────────────────────────────────────────────\n",
        "def prepare_and_convert(model, calib_loader, num_calib=5):\n",
        "    model.eval()\n",
        "    wrap_quantizable(model)\n",
        "    import torch.nn.functional as _F\n",
        "    for _, layer in get_approx_modules(model):\n",
        "        def fw(x, layer=layer):\n",
        "            w = layer.weight_hat.to(x.dtype)\n",
        "            b = getattr(layer, 'bias_hat', None)\n",
        "            return _F.conv2d(x, w, b.to(x.dtype) if b is not None else None,\n",
        "                             stride=layer.wrapped.stride,\n",
        "                             padding=layer.wrapped.padding,\n",
        "                             dilation=layer.wrapped.dilation,\n",
        "                             groups=layer.wrapped.groups)\n",
        "        layer.forward = fw.__get__(layer, layer.__class__)\n",
        "    mapping = tal.layer_mapping_dict()\n",
        "    quant.prepare(model, mapping)\n",
        "    with torch.no_grad():\n",
        "        for i, (imgs, _) in enumerate(calib_loader):\n",
        "            model(imgs.to(device))\n",
        "            if i + 1 >= num_calib: break\n",
        "    quant.convert(model, mapping)\n",
        "    return mapping\n",
        "\n",
        "def evaluate_variants(model, loader):\n",
        "    results = {}\n",
        "    for v, lut in luts.items():\n",
        "        for _, layer in get_approx_modules(model):\n",
        "            layer.inference_mode = tal.InferenceMode.QUANTIZED if v == 'Yang1' else tal.InferenceMode.APPROXIMATE\n",
        "            if v != 'Yang1':\n",
        "                layer.lut = lut\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labs in loader:\n",
        "                imgs, labs = imgs.to(device), labs.to(device)\n",
        "                pred = model(imgs).argmax(1)\n",
        "                correct += (pred == labs).sum().item()\n",
        "                total += labs.size(0)\n",
        "        results[v] = 100 * correct / total\n",
        "    return results\n",
        "\n",
        "# ─── 5. Train + Evaluate VGG8 ────────────────────────────────────────────\n",
        "print(\"\\n===== VGG8 =====\")\n",
        "model = VGG8().to(device)\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "for ep in range(3):\n",
        "    model.train()\n",
        "    for imgs, labs in train_loader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        opt.zero_grad()\n",
        "        F.cross_entropy(model(imgs), labs).backward()\n",
        "        opt.step()\n",
        "    print(f\"VGG8 Epoch {ep+1}/3 complete\")\n",
        "\n",
        "prepare_and_convert(model, calib_loader)\n",
        "results = evaluate_variants(model, test_loader)\n",
        "for v, acc in results.items():\n",
        "    print(f\"  {v:8s}: {acc:.2f}%\")\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxqX0RN0NxDd",
        "outputId": "5b83c95a-44d2-43e8-9aa3-bd9f20668683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\n",
            "===== VGG8 =====\n",
            "VGG8 Epoch 1/3 complete\n",
            "VGG8 Epoch 2/3 complete\n",
            "VGG8 Epoch 3/3 complete\n",
            "  Yang1   : 61.43%\n",
            "  Lin     : 61.35%\n",
            "  Ha      : 61.56%\n",
            "  Hybrid  : 61.42%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fE6kcveUOG8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}